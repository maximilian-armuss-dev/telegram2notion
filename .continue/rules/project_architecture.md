# ðŸ¤– KI-Entwicklungsrichtlinien (Projekt-Spezifisch) ðŸ¤–

---

## 1. ProjektÃ¼bersicht & Architektur

Bevor du arbeitest, mache dich mit dem Projekt vertraut.

### 1.1. High-Level-Ziel

Dieses Projekt ist ein asynchroner Python-Agent, der Nachrichten (Text und Sprache) aus einem Telegram-Chat extrahiert, sie mittels eines LLM und RAG in strukturierte Notion-DatenbankeintrÃ¤ge umwandelt und diese Ã¼ber die Notion-API synchronisiert.

### 1.2. Verzeichnisstruktur & Verantwortlichkeiten

Die gesamte Anwendungslogik befindet sich im Verzeichnis `/app`.

```
/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ processing/
â”‚   â”‚   â””â”€â”€ workflow_processor.py   # ðŸ’¡ HERZSTÃœCK: Orchestriert den gesamten Workflow
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ telegram_service.py     # Kapselt die Telegram Bot API
â”‚   â”‚   â”œâ”€â”€ gladia_service.py       # Kapselt die Gladia Speech-to-Text API
â”‚   â”‚   â”œâ”€â”€ llm_service.py          # Kapselt die Interaktion mit dem LLM (LangChain)
â”‚   â”‚   â”œâ”€â”€ notion_service.py       # Kapselt die Notion API
â”‚   â”‚   â””â”€â”€ vector_service.py       # Verwaltet die Vektor-Datenbank fÃ¼r RAG
â”‚   â”œâ”€â”€ config.py                   # âœ… Zentrales Laden der .env-Konfiguration
â”‚   â”œâ”€â”€ logging_config.py           # Konfiguration fÃ¼r das Logging-Modul
â”‚   â”œâ”€â”€ main.py                     # ðŸš€ Haupteinstiegspunkt der Anwendung
â”‚   â”œâ”€â”€ models.py                   # Pydantic-Datenmodelle fÃ¼r Notion-Strukturen
â”‚   â””â”€â”€ state_manager.py            # Verwaltet den Zustand (verarbeitete Nachrichten)
â”œâ”€â”€ prompts/                        # Speichert LLM-Prompts als .md-Dateien
â”œâ”€â”€ .env                            # Speichert alle Secrets und Konfigurationen und darf nie gelesen werden
â”œâ”€â”€ .env.example                    # Beispiel fÃ¼r eine .env Datei, darf gelesen werden
â””â”€â”€ ...
```

### 1.3. Kern-Workflow (End-to-End)

1.  **Start:** `main.py` ruft den `WorkflowProcessor` in `workflow_processor.py` auf.
2.  **Setup:** Der Prozessor initialisiert alle Services und baut den RAG-Vektorindex auf.
3.  **Fetch:** Neue Nachrichten werden von Telegram geholt.
4.  **Content Extraction:** Text wird direkt verwendet; Sprachnachrichten werden transkribiert.
5.  **RAG Context:** Relevante Dokumente werden Ã¼ber den `VectorService` aus Notion geholt.
6.  **LLM Processing:** Der `LLMService` generiert aus den Gedanken und dem Kontext eine Liste von validierten Notion-Aktionen.
7.  **Execution:** Der `NotionService` fÃ¼hrt diese Aktionen aus (create, update, archive).
8.  **State Update:** Die IDs der verarbeiteten Nachrichten werden gespeichert.

---

## 2. Architekturprinzipien

-   **Separation of Concerns:** Halte die Verantwortlichkeiten strikt getrennt. `workflow_processor.py` orchestriert nur. Die gesamte Logik fÃ¼r externe APIs (Telegram, Notion, Gladia) gehÃ¶rt ausschlieÃŸlich in die entsprechenden Service-Klassen in `/app/services`.
-   **Keine Hartcodierung:** Alle Konfigurationswerte, API-Keys, Dateipfade, Modellnamen oder "magische" Strings mÃ¼ssen aus der `.env`-Datei Ã¼ber das `settings`-Objekt aus `app/config.py` geladen werden.
-   **Logging Ã¼ber `print()`:** Die `print()`-Funktion ist verboten. Verwende fÃ¼r jegliche Ausgabe das `logging`-Modul (`logging.info`, `logging.error`).
-   **SDKs bevorzugen:** Nutze immer die offiziellen SDKs (`python-telegram-bot`, `notion-client`), anstatt direkte HTTP-Anfragen mit `httpx` oder `requests` zu implementieren.
